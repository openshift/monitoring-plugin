# Incidents Page Testing Checklist

This checklist covers regression testing for **known bug areas** in the Incidents page. Focus on sections 1-4 for critical regressions. Section 5 contains optional tests for stable areas.

**Incident Detection Known Bug Areas**:
- **Filtering**: Incidents were filtered by alert severity instead of incident's own severity history
- **Charts Display**: Tooltip positioning, bar sorting, and short alert visibility issues
- **API calls**: Alert resolution timing, silence matching logic (name+namespace+severity not just name)
- **Redux State Management**: Initialization race conditions, selection persistence, stale data, dropdown states




## How to Use This Checklist

1. **Set up test data first**: 
   - Copy the CSV from the "Complete Test Data" section below
   - Save it to a file and use with the simulation script from the `cluster-health-analyzer` repository.
2. **Identify relevant areas**: Based on the scope of the change, decide on areas that need to be targeted.   
3. **Run the tests**: Follow the test cases in order, checking expected vs actual behavior  
4. **Reference specific incidents**: Tests reference incidents by letter (A, B, C, etc.)

**Time notation**: All times are positive values in minutes. The simulation script adjusts them to be relative to "now".

---

## Complete Test Data - CSV Format

**Use this complete CSV with your simulation script to set up all test data at once:**

```csv
start,end,alertname,namespace,severity,silenced,labels
0,180,AlertA_Info,A-openshift-logging,info,false,{"component": "logging"}
240,360,AlertB_Warning,B-openshift-storage,warning,false,{"component": "storage"}
420,420,AlertC_ShortDuration,C-openshift-apiserver,warning,false,{"component": "api-server"}
480,780,AlertD_Info,D-openshift-monitoring,info,false,{"component": "monitoring"}
540,780,AlertD_Warning,D-openshift-monitoring,warning,false,{"component": "monitoring"}
600,780,AlertD_Critical,D-openshift-monitoring,critical,false,{"component": "monitoring"}
840,1080,AlertE_Etcd,-Eopenshift-etcd,critical,false,{"component": "etcd"}
840,1080,AlertE_KubeAPI,E-openshift-kube-apiserver,critical,false,{"component": "kube-apiserver"}
840,1080,AlertE_Controller_Very_Very_Very_Very_Long_Name_Alert,E-openshift-kube-controller,critical,false,{"component": "kube-controller"}
1140,1260,AlertF_KubePodCrashLooping,F-openshift-monitoring,warning,false,{"component": "monitoring"}
1200,1380,AlertF_HighMemoryUsage,F-openshift-monitoring,critical,false,{"component": "monitoring"}
1440,1500,AlertG_APIServerLatency,G-openshift-kube-apiserver,warning,false,{"component": "kube-apiserver"}
1560,1740,AlertH_Critical,H-openshift-network,critical,false,{"component": "network"}
1800,1980,AlertI_KubePodNotReady,I-openshift-operators,warning,true,{"component": "operators"}
2040,2220,AlertJ_KubePodNotReady,J-openshift-storage,warning,false,{"component": "storage"}
```

**What this creates** (incidents named A-J in chronological order):
- **Incident A** (0-180 min / 3 hrs): Info only, resolved - logging component
- **Incident B** (240-360 / 2 hrs): Warning only, resolved - storage component
- **Incident C** (420): Single data point, short duration - api-server component
- **Incident D** (480-780 / 5 hrs): Multi-severity transition (Info→Warning→Critical), firing - monitoring component
- **Incident E** (840-1080 / 4 hrs): Multi-component (3 alerts), resolved - etcd/kube-apiserver/kube-controller
- **Incident F** (1140-1380 / 4 hrs): Resolution testing (2 overlapping alerts) - monitoring component
- **Incident G** (1440-1500 / 1 hr): Short duration alert, resolved - kube-apiserver component
- **Incident H** (1560-1740 / 3 hrs): Critical, firing - network component
- **Incident I** (1800-1980 / 3 hrs): Silenced alert - operators component
- **Incident J** (2040-2220 / 3 hrs): NOT silenced (different namespace) - storage component

**Timeline** (37 hours total, NO overlaps between incidents, 60 min gaps):
```
0──────180──240───360──420──480──────780──840────1080──1140────1380──1440─1500──1560───1740──1800───1980──2040───2220
  A (3hr)  │ B(2hr) │ C │  D (5hr multi)  │ E (4hr x3) │  F (4hr test)  │ G(1hr) │  H(3hr)  │  I(3hr)  │  J(3hr)
           60min gap    60    60min gap      60min gap    60min gap         60       60min      60min      60min
```

**Format notes**:
- All times in minutes, positive values (simulation script adjusts to relative times)
- Alert names A-J match chronological order (A fires first, J fires last)
- NO overlaps between different incidents
- Alerts within same incident DO overlap (D has 3 overlapping alerts, E has 3 simultaneous, F has 2 overlapping)
- Long durations (1-5 hours) and large gaps (1 hour) ensure no unintended grouping
